---
title: "Team 17 Applied Exercise"
author: "Team 17"
date: "3/22/2021"
output:
  word_document: default
  html_document:
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls())
```

## Team 17 Exercise

We combined data from 9.6.2 and 9.6.4, and added an extra 4th class to create our dataframe

```{r}
set.seed(2021)
x = matrix(rnorm (200 * 2), ncol = 2)
x[1:100,] = x[1:100,] + 2
x[101:150,] = x[101:150,] - 2
y = c(rep(1,150), rep(2,50))

x = rbind(x, matrix(rnorm (50 * 2), ncol = 2))
y = c(y, rep(0, 50))
x[y == 0, 2] = x[y == 0, 2] + 2
dat = data.frame(x = x, y = as.factor(y))

x = rbind(x, matrix(rnorm (50 * 2), ncol = 2))
y = c(y, rep(3, 50))
x[y == 3, 2] = x[y == 3, 2] + 2
dat = data.frame(x = x, y = as.factor(y))

```

We plotted our data to determine if they are linearly separable or if the plot could show where the boundaries could be. 

```{r}
library(ggplot2)
ggplot(data = dat, aes(x = x[,1], y = x[,2], color = y, shape = y)) + 
  geom_point(size = 2) +
  scale_color_manual(values=c("red","dark green","blue","dark orange")) +
  theme(legend.position = "none")

```


```{r}
train <- sample(300,200) # 300 for the total samples, 200 for training the dataset. 
library(e1071) # Library that contains svm function
svmfit <- svm(y~., data=dat[train,], kernel='radial', gamma = 1, cost = 1)
plot(svmfit, dat[train,])
summary(svmfit)

```


```{r}
set.seed(1)
tune.out<- tune(svm, y~., data=dat[train,], kernel='radial', ranges=list(cost=c(0.1,1,10,100,1000), gamma=c(0.5,1,2,3,4)))
summary(tune.out)

```

From the output, it was determined the best model when cost = 1e+02, and gamma = 1.0
Based upon the model, let's test it with a testing set. 
```{r}
conf.mat <- table(true=dat[-train,'y'], pred=predict(tune.out$best.model, newdata=dat[-train,]))
library(caret)
confusionMatrix(conf.mat)

```

From our training and tunning method, our best model has a 65% accuracy rate. 